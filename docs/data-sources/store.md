---
# generated by https://github.com/hashicorp/terraform-plugin-docs
page_title: "deltastream_store Data Source - deltastream"
subcategory: ""
description: |-
  Store resource
---

# deltastream_store (Data Source)

Store resource



<!-- schema generated by tfplugindocs -->
## Schema

### Required

- `name` (String) Name of the Store

### Optional

- `confluent_kafka` (Attributes) Confluent Kafka specific configuration (see [below for nested schema](#nestedatt--confluent_kafka))
- `databricks` (Attributes) Databricks specific configuration (see [below for nested schema](#nestedatt--databricks))
- `kafka` (Attributes) Kafka specific configuration (see [below for nested schema](#nestedatt--kafka))
- `kinesis` (Attributes) Kinesis specific configuration (see [below for nested schema](#nestedatt--kinesis))
- `postgres` (Attributes) Postgres specific configuration (see [below for nested schema](#nestedatt--postgres))
- `snowflake` (Attributes) Snowflake specific configuration (see [below for nested schema](#nestedatt--snowflake))

### Read-Only

- `access_region` (String) Specifies the region of the Store. In order to improve latency and reduce data transfer costs, the region should be the same cloud and region that the physical Store is running in.
- `created_at` (String) Creation date of the Store
- `owner` (String) Owning role of the Store
- `state` (String) State of the Store
- `type` (String) Type of the Store
- `updated_at` (String) Last update date of the Store

<a id="nestedatt--confluent_kafka"></a>
### Nested Schema for `confluent_kafka`

Read-Only:

- `schema_registry_name` (String) Name of the schema registry
- `uris` (String) List of host:port URIs to connect to the store


<a id="nestedatt--databricks"></a>
### Nested Schema for `databricks`

Read-Only:

- `cloud_region` (String) The region where the S3 bucket is located
- `cloud_s3_bucket` (String) The name of the S3 bucket where the data will be stored
- `uris` (String) List of host:port URIs to connect to the store
- `warehouse_id` (String) The identifier for a Databricks SQL Warehouse belonging to a Databricks workspace. This Warehouse will be used to create and query Tables in Databricks


<a id="nestedatt--kafka"></a>
### Nested Schema for `kafka`

Read-Only:

- `schema_registry_name` (String) Name of the schema registry
- `tls_disabled` (Boolean) Specifies if the store should be accessed over TLS
- `tls_verify_server_hostname` (Boolean) Specifies if the server CNAME should be validated against the certificate
- `uris` (String) List of host:port URIs to connect to the store


<a id="nestedatt--kinesis"></a>
### Nested Schema for `kinesis`

Read-Only:

- `schema_registry_name` (String) Name of the schema registry
- `uris` (String) List of host:port URIs to connect to the store


<a id="nestedatt--postgres"></a>
### Nested Schema for `postgres`

Read-Only:

- `uris` (String) List of host:port URIs to connect to the store


<a id="nestedatt--snowflake"></a>
### Nested Schema for `snowflake`

Read-Only:

- `account_id` (String) Snowflake account ID
- `role_name` (String) Access control role to use for the Store operations after connecting to Snowflake
- `uris` (String) List of host:port URIs to connect to the store
- `warehouse_name` (String) Warehouse name to use for queries and other store operations that require compute resource
